# -*- coding: utf-8 -*-
"""classify_handwritten_letters.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Up8xU4MgcDBz_M3-jStg6tPdKOpCqXXT
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile

with zipfile.ZipFile("/content/drive/My Drive/5_projects/classify_handwritten_letters/letters.zip", 'r') as zip_ref:
    zip_ref.extractall("handwritten_letters")

import os
import pandas as pd
from PIL import Image
import numpy as np

dataset_path = "handwritten_letters"  # Folder where images are stored

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Define dataset path
data_path = "/content/drive/My Drive/5_projects/classify_handwritten_letters/handwritten_letters/letters/"

# Function to extract label from filename (modify based on actual dataset format)

def extract_label(filename):
    return filename.split("_")[-1][0] # Example: Extract 'A' from '01_04_00_A.png'

# Load images and labels
image_path = os.listdir(data_path)
x, y = [], []

for img_name in image_path:
    img_path = os.path.join(data_path, img_name)
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (32, 32))  # Resize to standard size
    img = img / 255.0
    x.append(img)
    y.append(extract_label(img_name))

print(np.array(x).shape)

# Convert to numpy arrays
x = np.array(x).reshape(-1, 32, 32, 1)
unique_labels = sorted(set(y))  # Get unique character labels
label_map = {char: idx for idx, char in enumerate(unique_labels)}  # Map labels to numbers
y = np.array([label_map[label] for label in y])
y = to_categorical(y, num_classes=len(unique_labels))

# Split into train and test sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Build CNN Model

model = keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(unique_labels), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# train Model

epochs = 10
batch_size = 32
history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))

# Evaluate model
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test accuracy: {test_acc}")
print(f"Test Loss: {test_loss}")

# Save model
model.save("handwritten_letters_model.h5")

# Make Predictions
predictions = model.predict(x_test[:25])  # Predict on the first 5 images
print(predictions)

predicted_classes = np.argmax(predictions, axis=1)
print(predicted_classes)  # Predicted classes

y_test_classes = np.argmax(y_test[:25], axis=1)  # Convert one-hot encoded labels to class indices

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Compute the confusion matrix
cm = confusion_matrix(y_test_classes, predicted_classes)

# Visualize the confusion matrix
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=range(25), yticklabels=range(25))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix for Handwritten Letter Classification')
plt.show()

